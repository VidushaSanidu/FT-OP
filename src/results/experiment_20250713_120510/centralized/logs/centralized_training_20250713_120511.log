[2025-07-13 12:05:11,380] [INFO] __main__: ================================================================================
[2025-07-13 12:05:11,380] [INFO] __main__: CENTRALIZED TRAINING FOR DO-TP MODEL
[2025-07-13 12:05:11,380] [INFO] __main__: ================================================================================
[2025-07-13 12:05:11,380] [INFO] __main__: Experiment: centralized_training_20250713_120510
[2025-07-13 12:05:11,380] [INFO] __main__: Training datasets: ['eth', 'hotel', 'zara1', 'zara2', 'univ']
[2025-07-13 12:05:11,380] [INFO] __main__: Validation dataset: zara1
[2025-07-13 12:05:11,380] [INFO] __main__: Output directory: ./results/experiment_20250713_120510/centralized
[2025-07-13 12:05:11,380] [INFO] __main__: Setting up data manager...
[2025-07-13 12:05:11,380] [INFO] core.data_manager: All required datasets are available
[2025-07-13 12:05:13,811] [INFO] core.data_manager: Loaded eth train dataset with 2785 samples
[2025-07-13 12:05:14,153] [INFO] core.data_manager: Loaded eth val dataset with 660 samples
[2025-07-13 12:05:14,397] [INFO] core.data_manager: Loaded eth test dataset with 70 samples
[2025-07-13 12:05:16,680] [INFO] core.data_manager: Loaded hotel train dataset with 2594 samples
[2025-07-13 12:05:17,011] [INFO] core.data_manager: Loaded hotel val dataset with 621 samples
[2025-07-13 12:05:17,366] [INFO] core.data_manager: Loaded hotel test dataset with 301 samples
[2025-07-13 12:05:19,670] [INFO] core.data_manager: Loaded zara1 train dataset with 2322 samples
[2025-07-13 12:05:20,011] [INFO] core.data_manager: Loaded zara1 val dataset with 605 samples
[2025-07-13 12:05:20,250] [INFO] core.data_manager: Loaded zara1 test dataset with 602 samples
[2025-07-13 12:05:22,392] [INFO] core.data_manager: Loaded zara2 train dataset with 2112 samples
[2025-07-13 12:05:22,687] [INFO] core.data_manager: Loaded zara2 val dataset with 501 samples
[2025-07-13 12:05:23,227] [INFO] core.data_manager: Loaded zara2 test dataset with 921 samples
[2025-07-13 12:05:24,384] [INFO] core.data_manager: Loaded univ train dataset with 2076 samples
[2025-07-13 12:05:24,596] [INFO] core.data_manager: Loaded univ val dataset with 530 samples
[2025-07-13 12:05:26,266] [INFO] core.data_manager: Loaded univ test dataset with 947 samples
[2025-07-13 12:05:26,267] [INFO] __main__: Dataset statistics:
[2025-07-13 12:05:26,267] [INFO] __main__:   eth: train=2785, val=660, test=70
[2025-07-13 12:05:26,267] [INFO] __main__:   hotel: train=2594, val=621, test=301
[2025-07-13 12:05:26,267] [INFO] __main__:   zara1: train=2322, val=605, test=602
[2025-07-13 12:05:26,267] [INFO] __main__:   zara2: train=2112, val=501, test=921
[2025-07-13 12:05:26,267] [INFO] __main__:   univ: train=2076, val=530, test=947
[2025-07-13 12:05:26,267] [INFO] __main__: Creating data loaders...
[2025-07-13 12:05:26,267] [INFO] core.data_manager: Preparing centralized training data from datasets: ['eth', 'hotel', 'zara1', 'zara2', 'univ']
[2025-07-13 12:05:28,682] [INFO] core.data_manager: Loaded eth train dataset with 2785 samples
[2025-07-13 12:05:28,683] [INFO] core.data_manager: Added eth: 2785 samples
[2025-07-13 12:05:30,971] [INFO] core.data_manager: Loaded hotel train dataset with 2594 samples
[2025-07-13 12:05:30,971] [INFO] core.data_manager: Added hotel: 2594 samples
[2025-07-13 12:05:33,316] [INFO] core.data_manager: Loaded zara1 train dataset with 2322 samples
[2025-07-13 12:05:33,316] [INFO] core.data_manager: Added zara1: 2322 samples
[2025-07-13 12:05:35,442] [INFO] core.data_manager: Loaded zara2 train dataset with 2112 samples
[2025-07-13 12:05:35,442] [INFO] core.data_manager: Added zara2: 2112 samples
[2025-07-13 12:05:36,666] [INFO] core.data_manager: Loaded univ train dataset with 2076 samples
[2025-07-13 12:05:36,666] [INFO] core.data_manager: Added univ: 2076 samples
[2025-07-13 12:05:36,666] [INFO] core.data_manager: Created centralized training loader with 11889 total samples
[2025-07-13 12:05:36,666] [INFO] core.data_manager: Preparing validation data from dataset: zara1
[2025-07-13 12:05:37,008] [INFO] core.data_manager: Loaded zara1 val dataset with 605 samples
[2025-07-13 12:05:37,008] [INFO] __main__: Training samples: 11889
[2025-07-13 12:05:37,008] [INFO] __main__: Validation samples: 605
[2025-07-13 12:05:37,008] [INFO] __main__: Creating model...
[2025-07-13 12:05:37,008] [INFO] core.training: Using CPU
[2025-07-13 12:05:37,009] [INFO] __main__: Model created with 36866 parameters
[2025-07-13 12:05:37,009] [INFO] __main__: Device: cpu
[2025-07-13 12:05:37,010] [INFO] __main__: Configuration saved to ./results/experiment_20250713_120510/centralized/centralized_training_20250713_120510_config.json
[2025-07-13 12:05:37,010] [INFO] __main__: Starting training...
[2025-07-13 12:05:37,439] [INFO] core.training: Starting training for 20 epochs
[2025-07-13 12:05:37,439] [INFO] core.training: Starting epoch 1/20
[2025-07-13 12:05:40,323] [INFO] core.training: Batch [50/186], Total Loss: 0.0204, Traj Loss: 0.0203, KL Loss: 0.0007
[2025-07-13 12:05:41,812] [INFO] core.training: Batch [100/186], Total Loss: 0.0118, Traj Loss: 0.0117, KL Loss: 0.0003
[2025-07-13 12:05:43,315] [INFO] core.training: Batch [150/186], Total Loss: 0.0119, Traj Loss: 0.0119, KL Loss: 0.0002
[2025-07-13 12:05:46,018] [INFO] core.training: Epoch [1/20] Train Loss: 0.0200, Val Loss: 0.0104, ADE: 1.2765, FDE: 2.4985, Time: 8.58s
[2025-07-13 12:05:46,021] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:05:46,022] [INFO] core.training: Starting epoch 2/20
[2025-07-13 12:05:48,510] [INFO] core.training: Batch [50/186], Total Loss: 0.0100, Traj Loss: 0.0100, KL Loss: 0.0001
[2025-07-13 12:05:50,041] [INFO] core.training: Batch [100/186], Total Loss: 0.0098, Traj Loss: 0.0098, KL Loss: 0.0001
[2025-07-13 12:05:51,567] [INFO] core.training: Batch [150/186], Total Loss: 0.0076, Traj Loss: 0.0076, KL Loss: 0.0001
[2025-07-13 12:05:54,341] [INFO] core.training: Epoch [2/20] Train Loss: 0.0101, Val Loss: 0.0100, ADE: 1.2747, FDE: 2.4952, Time: 8.32s
[2025-07-13 12:05:54,342] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:05:54,342] [INFO] core.training: Starting epoch 3/20
[2025-07-13 12:05:56,847] [INFO] core.training: Batch [50/186], Total Loss: 0.0087, Traj Loss: 0.0087, KL Loss: 0.0000
[2025-07-13 12:05:58,376] [INFO] core.training: Batch [100/186], Total Loss: 0.0083, Traj Loss: 0.0083, KL Loss: 0.0000
[2025-07-13 12:05:59,917] [INFO] core.training: Batch [150/186], Total Loss: 0.0093, Traj Loss: 0.0093, KL Loss: 0.0000
[2025-07-13 12:06:02,687] [INFO] core.training: Epoch [3/20] Train Loss: 0.0099, Val Loss: 0.0100, ADE: 1.2614, FDE: 2.4767, Time: 8.34s
[2025-07-13 12:06:02,688] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:06:02,688] [INFO] core.training: Starting epoch 4/20
[2025-07-13 12:06:05,166] [INFO] core.training: Batch [50/186], Total Loss: 0.0107, Traj Loss: 0.0107, KL Loss: 0.0000
[2025-07-13 12:06:06,716] [INFO] core.training: Batch [100/186], Total Loss: 0.0100, Traj Loss: 0.0100, KL Loss: 0.0000
[2025-07-13 12:06:08,267] [INFO] core.training: Batch [150/186], Total Loss: 0.0079, Traj Loss: 0.0079, KL Loss: 0.0000
[2025-07-13 12:06:11,068] [INFO] core.training: Epoch [4/20] Train Loss: 0.0098, Val Loss: 0.0096, ADE: 1.2685, FDE: 2.4920, Time: 8.38s
[2025-07-13 12:06:11,070] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:06:11,070] [INFO] core.training: Starting epoch 5/20
[2025-07-13 12:06:13,602] [INFO] core.training: Batch [50/186], Total Loss: 0.0110, Traj Loss: 0.0110, KL Loss: 0.0000
[2025-07-13 12:06:15,172] [INFO] core.training: Batch [100/186], Total Loss: 0.0088, Traj Loss: 0.0088, KL Loss: 0.0000
[2025-07-13 12:06:16,723] [INFO] core.training: Batch [150/186], Total Loss: 0.0072, Traj Loss: 0.0072, KL Loss: 0.0000
[2025-07-13 12:06:19,484] [INFO] core.training: Epoch [5/20] Train Loss: 0.0097, Val Loss: 0.0096, ADE: 1.2724, FDE: 2.4934, Time: 8.41s
[2025-07-13 12:06:19,484] [INFO] core.training: Starting epoch 6/20
[2025-07-13 12:06:21,939] [INFO] core.training: Batch [50/186], Total Loss: 0.0095, Traj Loss: 0.0095, KL Loss: 0.0000
[2025-07-13 12:06:23,483] [INFO] core.training: Batch [100/186], Total Loss: 0.0090, Traj Loss: 0.0090, KL Loss: 0.0000
[2025-07-13 12:06:25,070] [INFO] core.training: Batch [150/186], Total Loss: 0.0103, Traj Loss: 0.0103, KL Loss: 0.0000
[2025-07-13 12:06:27,876] [INFO] core.training: Epoch [6/20] Train Loss: 0.0097, Val Loss: 0.0094, ADE: 1.2660, FDE: 2.4877, Time: 8.39s
[2025-07-13 12:06:27,877] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:06:27,877] [INFO] core.training: Starting epoch 7/20
[2025-07-13 12:06:30,366] [INFO] core.training: Batch [50/186], Total Loss: 0.0086, Traj Loss: 0.0086, KL Loss: 0.0000
[2025-07-13 12:06:31,920] [INFO] core.training: Batch [100/186], Total Loss: 0.0092, Traj Loss: 0.0092, KL Loss: 0.0000
[2025-07-13 12:06:33,491] [INFO] core.training: Batch [150/186], Total Loss: 0.0092, Traj Loss: 0.0092, KL Loss: 0.0000
[2025-07-13 12:06:36,278] [INFO] core.training: Epoch [7/20] Train Loss: 0.0097, Val Loss: 0.0095, ADE: 1.2698, FDE: 2.4911, Time: 8.40s
[2025-07-13 12:06:36,279] [INFO] core.training: Starting epoch 8/20
[2025-07-13 12:06:38,792] [INFO] core.training: Batch [50/186], Total Loss: 0.0099, Traj Loss: 0.0099, KL Loss: 0.0000
[2025-07-13 12:06:40,376] [INFO] core.training: Batch [100/186], Total Loss: 0.0097, Traj Loss: 0.0097, KL Loss: 0.0000
[2025-07-13 12:06:41,916] [INFO] core.training: Batch [150/186], Total Loss: 0.0102, Traj Loss: 0.0102, KL Loss: 0.0000
[2025-07-13 12:06:44,728] [INFO] core.training: Epoch [8/20] Train Loss: 0.0096, Val Loss: 0.0094, ADE: 1.2740, FDE: 2.4968, Time: 8.45s
[2025-07-13 12:06:44,728] [INFO] core.training: Starting epoch 9/20
[2025-07-13 12:06:47,239] [INFO] core.training: Batch [50/186], Total Loss: 0.0090, Traj Loss: 0.0090, KL Loss: 0.0000
[2025-07-13 12:06:48,777] [INFO] core.training: Batch [100/186], Total Loss: 0.0102, Traj Loss: 0.0102, KL Loss: 0.0000
[2025-07-13 12:06:50,343] [INFO] core.training: Batch [150/186], Total Loss: 0.0096, Traj Loss: 0.0096, KL Loss: 0.0000
[2025-07-13 12:06:53,174] [INFO] core.training: Epoch [9/20] Train Loss: 0.0096, Val Loss: 0.0097, ADE: 1.2639, FDE: 2.4816, Time: 8.45s
[2025-07-13 12:06:53,174] [INFO] core.training: Starting epoch 10/20
[2025-07-13 12:06:55,688] [INFO] core.training: Batch [50/186], Total Loss: 0.0089, Traj Loss: 0.0089, KL Loss: 0.0000
[2025-07-13 12:06:57,233] [INFO] core.training: Batch [100/186], Total Loss: 0.0078, Traj Loss: 0.0078, KL Loss: 0.0000
[2025-07-13 12:06:58,783] [INFO] core.training: Batch [150/186], Total Loss: 0.0101, Traj Loss: 0.0101, KL Loss: 0.0000
[2025-07-13 12:07:01,597] [INFO] core.training: Epoch [10/20] Train Loss: 0.0096, Val Loss: 0.0094, ADE: 1.2735, FDE: 2.4970, Time: 8.42s
[2025-07-13 12:07:01,599] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:07:01,599] [INFO] core.training: Starting epoch 11/20
[2025-07-13 12:07:04,106] [INFO] core.training: Batch [50/186], Total Loss: 0.0105, Traj Loss: 0.0105, KL Loss: 0.0000
[2025-07-13 12:07:05,663] [INFO] core.training: Batch [100/186], Total Loss: 0.0098, Traj Loss: 0.0098, KL Loss: 0.0000
[2025-07-13 12:07:07,207] [INFO] core.training: Batch [150/186], Total Loss: 0.0100, Traj Loss: 0.0100, KL Loss: 0.0000
[2025-07-13 12:07:09,996] [INFO] core.training: Epoch [11/20] Train Loss: 0.0096, Val Loss: 0.0094, ADE: 1.2666, FDE: 2.4862, Time: 8.40s
[2025-07-13 12:07:09,997] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:07:09,997] [INFO] core.training: Starting epoch 12/20
[2025-07-13 12:07:12,482] [INFO] core.training: Batch [50/186], Total Loss: 0.0101, Traj Loss: 0.0101, KL Loss: 0.0000
[2025-07-13 12:07:14,030] [INFO] core.training: Batch [100/186], Total Loss: 0.0092, Traj Loss: 0.0092, KL Loss: 0.0000
[2025-07-13 12:07:15,607] [INFO] core.training: Batch [150/186], Total Loss: 0.0082, Traj Loss: 0.0082, KL Loss: 0.0000
[2025-07-13 12:07:18,415] [INFO] core.training: Epoch [12/20] Train Loss: 0.0095, Val Loss: 0.0093, ADE: 1.2676, FDE: 2.4874, Time: 8.42s
[2025-07-13 12:07:18,417] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:07:18,417] [INFO] core.training: Starting epoch 13/20
[2025-07-13 12:07:20,965] [INFO] core.training: Batch [50/186], Total Loss: 0.0085, Traj Loss: 0.0085, KL Loss: 0.0000
[2025-07-13 12:07:22,506] [INFO] core.training: Batch [100/186], Total Loss: 0.0087, Traj Loss: 0.0087, KL Loss: 0.0000
[2025-07-13 12:07:24,067] [INFO] core.training: Batch [150/186], Total Loss: 0.0090, Traj Loss: 0.0090, KL Loss: 0.0000
[2025-07-13 12:07:26,927] [INFO] core.training: Epoch [13/20] Train Loss: 0.0095, Val Loss: 0.0093, ADE: 1.2609, FDE: 2.4795, Time: 8.51s
[2025-07-13 12:07:26,928] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:07:26,928] [INFO] core.training: Starting epoch 14/20
[2025-07-13 12:07:29,474] [INFO] core.training: Batch [50/186], Total Loss: 0.0094, Traj Loss: 0.0094, KL Loss: 0.0000
[2025-07-13 12:07:31,020] [INFO] core.training: Batch [100/186], Total Loss: 0.0091, Traj Loss: 0.0091, KL Loss: 0.0000
[2025-07-13 12:07:32,568] [INFO] core.training: Batch [150/186], Total Loss: 0.0085, Traj Loss: 0.0085, KL Loss: 0.0000
[2025-07-13 12:07:35,369] [INFO] core.training: Epoch [14/20] Train Loss: 0.0095, Val Loss: 0.0093, ADE: 1.2591, FDE: 2.4775, Time: 8.44s
[2025-07-13 12:07:35,369] [INFO] core.training: Starting epoch 15/20
[2025-07-13 12:07:37,829] [INFO] core.training: Batch [50/186], Total Loss: 0.0100, Traj Loss: 0.0100, KL Loss: 0.0000
[2025-07-13 12:07:39,406] [INFO] core.training: Batch [100/186], Total Loss: 0.0097, Traj Loss: 0.0097, KL Loss: 0.0000
[2025-07-13 12:07:40,967] [INFO] core.training: Batch [150/186], Total Loss: 0.0088, Traj Loss: 0.0088, KL Loss: 0.0000
[2025-07-13 12:07:43,756] [INFO] core.training: Epoch [15/20] Train Loss: 0.0094, Val Loss: 0.0092, ADE: 1.2700, FDE: 2.4925, Time: 8.39s
[2025-07-13 12:07:43,757] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:07:43,757] [INFO] core.training: Starting epoch 16/20
[2025-07-13 12:07:46,295] [INFO] core.training: Batch [50/186], Total Loss: 0.0112, Traj Loss: 0.0112, KL Loss: 0.0000
[2025-07-13 12:07:47,869] [INFO] core.training: Batch [100/186], Total Loss: 0.0096, Traj Loss: 0.0096, KL Loss: 0.0000
[2025-07-13 12:07:49,406] [INFO] core.training: Batch [150/186], Total Loss: 0.0085, Traj Loss: 0.0085, KL Loss: 0.0000
[2025-07-13 12:07:52,251] [INFO] core.training: Epoch [16/20] Train Loss: 0.0094, Val Loss: 0.0091, ADE: 1.2647, FDE: 2.4845, Time: 8.49s
[2025-07-13 12:07:52,253] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:07:52,253] [INFO] core.training: Starting epoch 17/20
[2025-07-13 12:07:54,780] [INFO] core.training: Batch [50/186], Total Loss: 0.0097, Traj Loss: 0.0097, KL Loss: 0.0000
[2025-07-13 12:07:56,338] [INFO] core.training: Batch [100/186], Total Loss: 0.0093, Traj Loss: 0.0093, KL Loss: 0.0000
[2025-07-13 12:07:57,916] [INFO] core.training: Batch [150/186], Total Loss: 0.0100, Traj Loss: 0.0100, KL Loss: 0.0000
[2025-07-13 12:08:00,738] [INFO] core.training: Epoch [17/20] Train Loss: 0.0094, Val Loss: 0.0093, ADE: 1.2746, FDE: 2.4973, Time: 8.49s
[2025-07-13 12:08:00,739] [INFO] core.training: Starting epoch 18/20
[2025-07-13 12:08:03,228] [INFO] core.training: Batch [50/186], Total Loss: 0.0086, Traj Loss: 0.0086, KL Loss: 0.0000
[2025-07-13 12:08:04,823] [INFO] core.training: Batch [100/186], Total Loss: 0.0100, Traj Loss: 0.0100, KL Loss: 0.0000
[2025-07-13 12:08:06,393] [INFO] core.training: Batch [150/186], Total Loss: 0.0107, Traj Loss: 0.0107, KL Loss: 0.0000
[2025-07-13 12:08:09,219] [INFO] core.training: Epoch [18/20] Train Loss: 0.0093, Val Loss: 0.0090, ADE: 1.2656, FDE: 2.4852, Time: 8.48s
[2025-07-13 12:08:09,220] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:08:09,220] [INFO] core.training: Starting epoch 19/20
[2025-07-13 12:08:11,759] [INFO] core.training: Batch [50/186], Total Loss: 0.0078, Traj Loss: 0.0078, KL Loss: 0.0000
[2025-07-13 12:08:13,347] [INFO] core.training: Batch [100/186], Total Loss: 0.0086, Traj Loss: 0.0086, KL Loss: 0.0000
[2025-07-13 12:08:14,940] [INFO] core.training: Batch [150/186], Total Loss: 0.0087, Traj Loss: 0.0087, KL Loss: 0.0000
[2025-07-13 12:08:17,702] [INFO] core.training: Epoch [19/20] Train Loss: 0.0093, Val Loss: 0.0090, ADE: 1.2666, FDE: 2.4870, Time: 8.48s
[2025-07-13 12:08:17,703] [INFO] core.training: Best model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_best.pt
[2025-07-13 12:08:17,703] [INFO] core.training: Starting epoch 20/20
[2025-07-13 12:08:20,219] [INFO] core.training: Batch [50/186], Total Loss: 0.0090, Traj Loss: 0.0090, KL Loss: 0.0000
[2025-07-13 12:08:21,803] [INFO] core.training: Batch [100/186], Total Loss: 0.0102, Traj Loss: 0.0102, KL Loss: 0.0000
[2025-07-13 12:08:23,444] [INFO] core.training: Batch [150/186], Total Loss: 0.0087, Traj Loss: 0.0087, KL Loss: 0.0000
[2025-07-13 12:08:26,260] [INFO] core.training: Epoch [20/20] Train Loss: 0.0092, Val Loss: 0.0092, ADE: 1.2719, FDE: 2.4920, Time: 8.56s
[2025-07-13 12:08:26,261] [INFO] __main__: Training completed!
[2025-07-13 12:08:26,261] [INFO] __main__: Best validation metrics:
[2025-07-13 12:08:26,261] [INFO] __main__:   Epoch: 19
[2025-07-13 12:08:26,261] [INFO] __main__:   Loss: 0.0090
[2025-07-13 12:08:26,261] [INFO] __main__:   ADE: 1.2666
[2025-07-13 12:08:26,261] [INFO] __main__:   FDE: 2.4870
[2025-07-13 12:08:26,261] [INFO] __main__:   Total training time: 168.80s
[2025-07-13 12:08:26,261] [INFO] __main__: Creating training plots...
[2025-07-13 12:08:26,761] [INFO] core.evaluation: Saved training curves for centralized_training_20250713_120510
[2025-07-13 12:08:26,998] [INFO] core.evaluation: Saved validation metrics for centralized_training_20250713_120510
[2025-07-13 12:08:26,999] [INFO] __main__: Final model saved to ./results/experiment_20250713_120510/centralized/do_tp_centralized_final.pt
[2025-07-13 12:08:26,999] [ERROR] __main__: Training failed with error: Object of type int64 is not JSON serializable
