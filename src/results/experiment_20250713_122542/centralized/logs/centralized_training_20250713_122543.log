[2025-07-13 12:25:43,201] [INFO] __main__: ================================================================================
[2025-07-13 12:25:43,201] [INFO] __main__: CENTRALIZED TRAINING FOR DO-TP MODEL
[2025-07-13 12:25:43,201] [INFO] __main__: ================================================================================
[2025-07-13 12:25:43,201] [INFO] __main__: Experiment: centralized_training_20250713_122542
[2025-07-13 12:25:43,201] [INFO] __main__: Training datasets: ['eth', 'hotel', 'zara1', 'zara2', 'univ']
[2025-07-13 12:25:43,201] [INFO] __main__: Validation dataset: zara1
[2025-07-13 12:25:43,201] [INFO] __main__: Output directory: ./results/experiment_20250713_122542/centralized
[2025-07-13 12:25:43,202] [INFO] __main__: Setting up data manager...
[2025-07-13 12:25:43,202] [INFO] core.data_manager: All required datasets are available
[2025-07-13 12:25:45,640] [INFO] core.data_manager: Loaded eth train dataset with 2785 samples
[2025-07-13 12:25:45,981] [INFO] core.data_manager: Loaded eth val dataset with 660 samples
[2025-07-13 12:25:46,228] [INFO] core.data_manager: Loaded eth test dataset with 70 samples
[2025-07-13 12:25:48,538] [INFO] core.data_manager: Loaded hotel train dataset with 2594 samples
[2025-07-13 12:25:48,870] [INFO] core.data_manager: Loaded hotel val dataset with 621 samples
[2025-07-13 12:25:49,227] [INFO] core.data_manager: Loaded hotel test dataset with 301 samples
[2025-07-13 12:25:51,557] [INFO] core.data_manager: Loaded zara1 train dataset with 2322 samples
[2025-07-13 12:25:51,901] [INFO] core.data_manager: Loaded zara1 val dataset with 605 samples
[2025-07-13 12:25:52,141] [INFO] core.data_manager: Loaded zara1 test dataset with 602 samples
[2025-07-13 12:25:54,296] [INFO] core.data_manager: Loaded zara2 train dataset with 2112 samples
[2025-07-13 12:25:54,594] [INFO] core.data_manager: Loaded zara2 val dataset with 501 samples
[2025-07-13 12:25:55,135] [INFO] core.data_manager: Loaded zara2 test dataset with 921 samples
[2025-07-13 12:25:56,296] [INFO] core.data_manager: Loaded univ train dataset with 2076 samples
[2025-07-13 12:25:56,507] [INFO] core.data_manager: Loaded univ val dataset with 530 samples
[2025-07-13 12:25:58,193] [INFO] core.data_manager: Loaded univ test dataset with 947 samples
[2025-07-13 12:25:58,194] [INFO] __main__: Dataset statistics:
[2025-07-13 12:25:58,194] [INFO] __main__:   eth: train=2785, val=660, test=70
[2025-07-13 12:25:58,194] [INFO] __main__:   hotel: train=2594, val=621, test=301
[2025-07-13 12:25:58,194] [INFO] __main__:   zara1: train=2322, val=605, test=602
[2025-07-13 12:25:58,194] [INFO] __main__:   zara2: train=2112, val=501, test=921
[2025-07-13 12:25:58,194] [INFO] __main__:   univ: train=2076, val=530, test=947
[2025-07-13 12:25:58,194] [INFO] __main__: Creating data loaders...
[2025-07-13 12:25:58,194] [INFO] core.data_manager: Preparing centralized training data from datasets: ['eth', 'hotel', 'zara1', 'zara2', 'univ']
[2025-07-13 12:26:00,583] [INFO] core.data_manager: Loaded eth train dataset with 2785 samples
[2025-07-13 12:26:00,584] [INFO] core.data_manager: Added eth: 2785 samples
[2025-07-13 12:26:02,883] [INFO] core.data_manager: Loaded hotel train dataset with 2594 samples
[2025-07-13 12:26:02,883] [INFO] core.data_manager: Added hotel: 2594 samples
[2025-07-13 12:26:05,240] [INFO] core.data_manager: Loaded zara1 train dataset with 2322 samples
[2025-07-13 12:26:05,240] [INFO] core.data_manager: Added zara1: 2322 samples
[2025-07-13 12:26:07,376] [INFO] core.data_manager: Loaded zara2 train dataset with 2112 samples
[2025-07-13 12:26:07,376] [INFO] core.data_manager: Added zara2: 2112 samples
[2025-07-13 12:26:08,536] [INFO] core.data_manager: Loaded univ train dataset with 2076 samples
[2025-07-13 12:26:08,536] [INFO] core.data_manager: Added univ: 2076 samples
[2025-07-13 12:26:08,537] [INFO] core.data_manager: Created centralized training loader with 11889 total samples
[2025-07-13 12:26:08,537] [INFO] core.data_manager: Preparing validation data from dataset: zara1
[2025-07-13 12:26:08,881] [INFO] core.data_manager: Loaded zara1 val dataset with 605 samples
[2025-07-13 12:26:08,881] [INFO] __main__: Training samples: 11889
[2025-07-13 12:26:08,881] [INFO] __main__: Validation samples: 605
[2025-07-13 12:26:08,881] [INFO] __main__: Creating model...
[2025-07-13 12:26:08,881] [INFO] core.training: Using CPU
[2025-07-13 12:26:08,882] [INFO] __main__: Model created with 36866 parameters
[2025-07-13 12:26:08,882] [INFO] __main__: Device: cpu
[2025-07-13 12:26:08,882] [INFO] __main__: Configuration saved to ./results/experiment_20250713_122542/centralized/centralized_training_20250713_122542_config.json
[2025-07-13 12:26:08,882] [INFO] __main__: Starting training...
[2025-07-13 12:26:09,311] [INFO] core.training: Starting training for 20 epochs
[2025-07-13 12:26:09,311] [INFO] core.training: Starting epoch 1/20
[2025-07-13 12:26:12,004] [INFO] core.training: Batch [50/186], Total Loss: 0.0124, Traj Loss: 0.0123, KL Loss: 0.0007
[2025-07-13 12:26:13,511] [INFO] core.training: Batch [100/186], Total Loss: 0.0112, Traj Loss: 0.0111, KL Loss: 0.0003
[2025-07-13 12:26:15,021] [INFO] core.training: Batch [150/186], Total Loss: 0.0089, Traj Loss: 0.0089, KL Loss: 0.0001
[2025-07-13 12:26:17,773] [INFO] core.training: Epoch [1/20] Train Loss: 0.0152, Val Loss: 0.0100, ADE: 1.2666, FDE: 2.4851, Time: 8.46s
[2025-07-13 12:26:17,776] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:26:17,776] [INFO] core.training: Starting epoch 2/20
[2025-07-13 12:26:20,251] [INFO] core.training: Batch [50/186], Total Loss: 0.0093, Traj Loss: 0.0093, KL Loss: 0.0001
[2025-07-13 12:26:21,783] [INFO] core.training: Batch [100/186], Total Loss: 0.0102, Traj Loss: 0.0102, KL Loss: 0.0001
[2025-07-13 12:26:23,394] [INFO] core.training: Batch [150/186], Total Loss: 0.0093, Traj Loss: 0.0093, KL Loss: 0.0000
[2025-07-13 12:26:26,163] [INFO] core.training: Epoch [2/20] Train Loss: 0.0100, Val Loss: 0.0096, ADE: 1.2697, FDE: 2.4905, Time: 8.39s
[2025-07-13 12:26:26,164] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:26:26,164] [INFO] core.training: Starting epoch 3/20
[2025-07-13 12:26:28,691] [INFO] core.training: Batch [50/186], Total Loss: 0.0086, Traj Loss: 0.0086, KL Loss: 0.0000
[2025-07-13 12:26:30,251] [INFO] core.training: Batch [100/186], Total Loss: 0.0095, Traj Loss: 0.0095, KL Loss: 0.0000
[2025-07-13 12:26:31,756] [INFO] core.training: Batch [150/186], Total Loss: 0.0095, Traj Loss: 0.0095, KL Loss: 0.0000
[2025-07-13 12:26:34,549] [INFO] core.training: Epoch [3/20] Train Loss: 0.0099, Val Loss: 0.0095, ADE: 1.2712, FDE: 2.4928, Time: 8.38s
[2025-07-13 12:26:34,550] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:26:34,550] [INFO] core.training: Starting epoch 4/20
[2025-07-13 12:26:37,055] [INFO] core.training: Batch [50/186], Total Loss: 0.0101, Traj Loss: 0.0101, KL Loss: 0.0000
[2025-07-13 12:26:38,584] [INFO] core.training: Batch [100/186], Total Loss: 0.0093, Traj Loss: 0.0093, KL Loss: 0.0000
[2025-07-13 12:26:40,109] [INFO] core.training: Batch [150/186], Total Loss: 0.0108, Traj Loss: 0.0108, KL Loss: 0.0000
[2025-07-13 12:26:42,863] [INFO] core.training: Epoch [4/20] Train Loss: 0.0098, Val Loss: 0.0095, ADE: 1.2717, FDE: 2.4949, Time: 8.31s
[2025-07-13 12:26:42,865] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:26:42,865] [INFO] core.training: Starting epoch 5/20
[2025-07-13 12:26:45,372] [INFO] core.training: Batch [50/186], Total Loss: 0.0090, Traj Loss: 0.0090, KL Loss: 0.0000
[2025-07-13 12:26:46,913] [INFO] core.training: Batch [100/186], Total Loss: 0.0102, Traj Loss: 0.0102, KL Loss: 0.0000
[2025-07-13 12:26:48,455] [INFO] core.training: Batch [150/186], Total Loss: 0.0108, Traj Loss: 0.0108, KL Loss: 0.0000
[2025-07-13 12:26:51,224] [INFO] core.training: Epoch [5/20] Train Loss: 0.0097, Val Loss: 0.0096, ADE: 1.2642, FDE: 2.4840, Time: 8.36s
[2025-07-13 12:26:51,224] [INFO] core.training: Starting epoch 6/20
[2025-07-13 12:26:53,718] [INFO] core.training: Batch [50/186], Total Loss: 0.0097, Traj Loss: 0.0097, KL Loss: 0.0000
[2025-07-13 12:26:55,258] [INFO] core.training: Batch [100/186], Total Loss: 0.0096, Traj Loss: 0.0096, KL Loss: 0.0000
[2025-07-13 12:26:56,767] [INFO] core.training: Batch [150/186], Total Loss: 0.0094, Traj Loss: 0.0094, KL Loss: 0.0000
[2025-07-13 12:26:59,529] [INFO] core.training: Epoch [6/20] Train Loss: 0.0097, Val Loss: 0.0095, ADE: 1.2669, FDE: 2.4874, Time: 8.30s
[2025-07-13 12:26:59,530] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:26:59,530] [INFO] core.training: Starting epoch 7/20
[2025-07-13 12:27:02,033] [INFO] core.training: Batch [50/186], Total Loss: 0.0100, Traj Loss: 0.0100, KL Loss: 0.0000
[2025-07-13 12:27:03,565] [INFO] core.training: Batch [100/186], Total Loss: 0.0093, Traj Loss: 0.0093, KL Loss: 0.0000
[2025-07-13 12:27:05,097] [INFO] core.training: Batch [150/186], Total Loss: 0.0081, Traj Loss: 0.0081, KL Loss: 0.0000
[2025-07-13 12:27:07,847] [INFO] core.training: Epoch [7/20] Train Loss: 0.0097, Val Loss: 0.0095, ADE: 1.2677, FDE: 2.4885, Time: 8.32s
[2025-07-13 12:27:07,848] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:27:07,848] [INFO] core.training: Starting epoch 8/20
[2025-07-13 12:27:10,295] [INFO] core.training: Batch [50/186], Total Loss: 0.0080, Traj Loss: 0.0080, KL Loss: 0.0000
[2025-07-13 12:27:11,811] [INFO] core.training: Batch [100/186], Total Loss: 0.0106, Traj Loss: 0.0106, KL Loss: 0.0000
[2025-07-13 12:27:13,346] [INFO] core.training: Batch [150/186], Total Loss: 0.0088, Traj Loss: 0.0088, KL Loss: 0.0000
[2025-07-13 12:27:16,135] [INFO] core.training: Epoch [8/20] Train Loss: 0.0096, Val Loss: 0.0097, ADE: 1.2692, FDE: 2.4907, Time: 8.29s
[2025-07-13 12:27:16,135] [INFO] core.training: Starting epoch 9/20
[2025-07-13 12:27:18,570] [INFO] core.training: Batch [50/186], Total Loss: 0.0071, Traj Loss: 0.0071, KL Loss: 0.0000
[2025-07-13 12:27:20,112] [INFO] core.training: Batch [100/186], Total Loss: 0.0083, Traj Loss: 0.0083, KL Loss: 0.0000
[2025-07-13 12:27:21,653] [INFO] core.training: Batch [150/186], Total Loss: 0.0108, Traj Loss: 0.0108, KL Loss: 0.0000
[2025-07-13 12:27:24,423] [INFO] core.training: Epoch [9/20] Train Loss: 0.0095, Val Loss: 0.0093, ADE: 1.2650, FDE: 2.4836, Time: 8.29s
[2025-07-13 12:27:24,425] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:27:24,425] [INFO] core.training: Starting epoch 10/20
[2025-07-13 12:27:26,913] [INFO] core.training: Batch [50/186], Total Loss: 0.0101, Traj Loss: 0.0101, KL Loss: 0.0000
[2025-07-13 12:27:28,490] [INFO] core.training: Batch [100/186], Total Loss: 0.0089, Traj Loss: 0.0089, KL Loss: 0.0000
[2025-07-13 12:27:30,023] [INFO] core.training: Batch [150/186], Total Loss: 0.0112, Traj Loss: 0.0112, KL Loss: 0.0000
[2025-07-13 12:27:32,780] [INFO] core.training: Epoch [10/20] Train Loss: 0.0095, Val Loss: 0.0093, ADE: 1.2641, FDE: 2.4837, Time: 8.35s
[2025-07-13 12:27:32,780] [INFO] core.training: Starting epoch 11/20
[2025-07-13 12:27:35,248] [INFO] core.training: Batch [50/186], Total Loss: 0.0096, Traj Loss: 0.0096, KL Loss: 0.0000
[2025-07-13 12:27:36,772] [INFO] core.training: Batch [100/186], Total Loss: 0.0086, Traj Loss: 0.0086, KL Loss: 0.0000
[2025-07-13 12:27:38,308] [INFO] core.training: Batch [150/186], Total Loss: 0.0084, Traj Loss: 0.0084, KL Loss: 0.0000
[2025-07-13 12:27:41,081] [INFO] core.training: Epoch [11/20] Train Loss: 0.0095, Val Loss: 0.0093, ADE: 1.2639, FDE: 2.4807, Time: 8.30s
[2025-07-13 12:27:41,082] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:27:41,083] [INFO] core.training: Starting epoch 12/20
[2025-07-13 12:27:43,578] [INFO] core.training: Batch [50/186], Total Loss: 0.0089, Traj Loss: 0.0089, KL Loss: 0.0000
[2025-07-13 12:27:45,108] [INFO] core.training: Batch [100/186], Total Loss: 0.0099, Traj Loss: 0.0099, KL Loss: 0.0000
[2025-07-13 12:27:46,624] [INFO] core.training: Batch [150/186], Total Loss: 0.0108, Traj Loss: 0.0108, KL Loss: 0.0000
[2025-07-13 12:27:49,388] [INFO] core.training: Epoch [12/20] Train Loss: 0.0095, Val Loss: 0.0093, ADE: 1.2690, FDE: 2.4896, Time: 8.31s
[2025-07-13 12:27:49,389] [INFO] core.training: Starting epoch 13/20
[2025-07-13 12:27:51,835] [INFO] core.training: Batch [50/186], Total Loss: 0.0091, Traj Loss: 0.0091, KL Loss: 0.0000
[2025-07-13 12:27:53,377] [INFO] core.training: Batch [100/186], Total Loss: 0.0114, Traj Loss: 0.0114, KL Loss: 0.0000
[2025-07-13 12:27:54,907] [INFO] core.training: Batch [150/186], Total Loss: 0.0101, Traj Loss: 0.0101, KL Loss: 0.0000
[2025-07-13 12:27:57,665] [INFO] core.training: Epoch [13/20] Train Loss: 0.0094, Val Loss: 0.0094, ADE: 1.2582, FDE: 2.4728, Time: 8.28s
[2025-07-13 12:27:57,665] [INFO] core.training: Starting epoch 14/20
[2025-07-13 12:28:00,119] [INFO] core.training: Batch [50/186], Total Loss: 0.0078, Traj Loss: 0.0078, KL Loss: 0.0000
[2025-07-13 12:28:01,641] [INFO] core.training: Batch [100/186], Total Loss: 0.0102, Traj Loss: 0.0102, KL Loss: 0.0000
[2025-07-13 12:28:03,161] [INFO] core.training: Batch [150/186], Total Loss: 0.0090, Traj Loss: 0.0090, KL Loss: 0.0000
[2025-07-13 12:28:05,958] [INFO] core.training: Epoch [14/20] Train Loss: 0.0095, Val Loss: 0.0094, ADE: 1.2729, FDE: 2.4958, Time: 8.29s
[2025-07-13 12:28:05,959] [INFO] core.training: Starting epoch 15/20
[2025-07-13 12:28:08,445] [INFO] core.training: Batch [50/186], Total Loss: 0.0087, Traj Loss: 0.0087, KL Loss: 0.0000
[2025-07-13 12:28:10,043] [INFO] core.training: Batch [100/186], Total Loss: 0.0088, Traj Loss: 0.0088, KL Loss: 0.0000
[2025-07-13 12:28:11,573] [INFO] core.training: Batch [150/186], Total Loss: 0.0086, Traj Loss: 0.0086, KL Loss: 0.0000
[2025-07-13 12:28:14,295] [INFO] core.training: Epoch [15/20] Train Loss: 0.0094, Val Loss: 0.0093, ADE: 1.2647, FDE: 2.4828, Time: 8.34s
[2025-07-13 12:28:14,296] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:28:14,296] [INFO] core.training: Starting epoch 16/20
[2025-07-13 12:28:16,783] [INFO] core.training: Batch [50/186], Total Loss: 0.0093, Traj Loss: 0.0093, KL Loss: 0.0000
[2025-07-13 12:28:18,313] [INFO] core.training: Batch [100/186], Total Loss: 0.0097, Traj Loss: 0.0097, KL Loss: 0.0000
[2025-07-13 12:28:19,862] [INFO] core.training: Batch [150/186], Total Loss: 0.0092, Traj Loss: 0.0092, KL Loss: 0.0000
[2025-07-13 12:28:22,623] [INFO] core.training: Epoch [16/20] Train Loss: 0.0094, Val Loss: 0.0092, ADE: 1.2646, FDE: 2.4852, Time: 8.33s
[2025-07-13 12:28:22,624] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:28:22,624] [INFO] core.training: Starting epoch 17/20
[2025-07-13 12:28:25,104] [INFO] core.training: Batch [50/186], Total Loss: 0.0102, Traj Loss: 0.0102, KL Loss: 0.0000
[2025-07-13 12:28:26,650] [INFO] core.training: Batch [100/186], Total Loss: 0.0092, Traj Loss: 0.0092, KL Loss: 0.0000
[2025-07-13 12:28:28,242] [INFO] core.training: Batch [150/186], Total Loss: 0.0096, Traj Loss: 0.0096, KL Loss: 0.0000
[2025-07-13 12:28:31,001] [INFO] core.training: Epoch [17/20] Train Loss: 0.0094, Val Loss: 0.0092, ADE: 1.2696, FDE: 2.4899, Time: 8.38s
[2025-07-13 12:28:31,001] [INFO] core.training: Starting epoch 18/20
[2025-07-13 12:28:33,478] [INFO] core.training: Batch [50/186], Total Loss: 0.0102, Traj Loss: 0.0102, KL Loss: 0.0000
[2025-07-13 12:28:35,017] [INFO] core.training: Batch [100/186], Total Loss: 0.0089, Traj Loss: 0.0089, KL Loss: 0.0000
[2025-07-13 12:28:36,546] [INFO] core.training: Batch [150/186], Total Loss: 0.0097, Traj Loss: 0.0097, KL Loss: 0.0000
[2025-07-13 12:28:39,311] [INFO] core.training: Epoch [18/20] Train Loss: 0.0094, Val Loss: 0.0094, ADE: 1.2654, FDE: 2.4840, Time: 8.31s
[2025-07-13 12:28:39,311] [INFO] core.training: Starting epoch 19/20
[2025-07-13 12:28:41,774] [INFO] core.training: Batch [50/186], Total Loss: 0.0088, Traj Loss: 0.0088, KL Loss: 0.0000
[2025-07-13 12:28:43,313] [INFO] core.training: Batch [100/186], Total Loss: 0.0111, Traj Loss: 0.0111, KL Loss: 0.0000
[2025-07-13 12:28:44,841] [INFO] core.training: Batch [150/186], Total Loss: 0.0096, Traj Loss: 0.0096, KL Loss: 0.0000
[2025-07-13 12:28:47,586] [INFO] core.training: Epoch [19/20] Train Loss: 0.0093, Val Loss: 0.0092, ADE: 1.2652, FDE: 2.4840, Time: 8.27s
[2025-07-13 12:28:47,587] [INFO] core.training: Best model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_best.pt
[2025-07-13 12:28:47,587] [INFO] core.training: Starting epoch 20/20
[2025-07-13 12:28:50,059] [INFO] core.training: Batch [50/186], Total Loss: 0.0079, Traj Loss: 0.0079, KL Loss: 0.0000
[2025-07-13 12:28:51,577] [INFO] core.training: Batch [100/186], Total Loss: 0.0093, Traj Loss: 0.0093, KL Loss: 0.0000
[2025-07-13 12:28:53,115] [INFO] core.training: Batch [150/186], Total Loss: 0.0098, Traj Loss: 0.0098, KL Loss: 0.0000
[2025-07-13 12:28:55,890] [INFO] core.training: Epoch [20/20] Train Loss: 0.0093, Val Loss: 0.0092, ADE: 1.2640, FDE: 2.4820, Time: 8.30s
[2025-07-13 12:28:55,890] [INFO] __main__: Training completed!
[2025-07-13 12:28:55,890] [INFO] __main__: Best validation metrics:
[2025-07-13 12:28:55,890] [INFO] __main__:   Epoch: 19
[2025-07-13 12:28:55,890] [INFO] __main__:   Loss: 0.0092
[2025-07-13 12:28:55,891] [INFO] __main__:   ADE: 1.2652
[2025-07-13 12:28:55,891] [INFO] __main__:   FDE: 2.4840
[2025-07-13 12:28:55,891] [INFO] __main__:   Total training time: 166.56s
[2025-07-13 12:28:55,891] [INFO] __main__: Creating training plots...
[2025-07-13 12:28:56,377] [INFO] core.evaluation: Saved training curves for centralized_training_20250713_122542
[2025-07-13 12:28:56,614] [INFO] core.evaluation: Saved validation metrics for centralized_training_20250713_122542
[2025-07-13 12:28:56,615] [INFO] __main__: Final model saved to ./results/experiment_20250713_122542/centralized/do_tp_centralized_final.pt
[2025-07-13 12:28:56,615] [INFO] __main__: Training metrics saved to ./results/experiment_20250713_122542/centralized/centralized_training_20250713_122542_metrics.json
[2025-07-13 12:28:56,616] [INFO] __main__: Centralized training completed successfully!
